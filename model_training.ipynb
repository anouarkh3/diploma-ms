{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "75df50e8",
   "metadata": {
    "papermill": {
     "duration": 17.328168,
     "end_time": "2024-04-09T07:43:38.787831",
     "exception": false,
     "start_time": "2024-04-09T07:43:21.459663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import torch\n",
    "import random\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f462cd26",
   "metadata": {
    "papermill": {
     "duration": 0.016851,
     "end_time": "2024-04-09T07:43:38.811382",
     "exception": false,
     "start_time": "2024-04-09T07:43:38.794531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_everything(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a3935fd8",
   "metadata": {
    "papermill": {
     "duration": 0.016748,
     "end_time": "2024-04-09T07:43:38.834378",
     "exception": false,
     "start_time": "2024-04-09T07:43:38.817630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Source: https://www.kaggle.com/davids1992/specaugment-quick-implementation\n",
    "def spec_augment(spec: np.ndarray,\n",
    "                 num_mask=2,\n",
    "                 freq_masking=0.15,\n",
    "                 time_masking=0.20,\n",
    "                 value=0):\n",
    "    spec = spec.copy()\n",
    "    num_mask = random.randint(1, num_mask)\n",
    "    for i in range(num_mask):\n",
    "        all_freqs_num, all_frames_num  = spec.shape\n",
    "        freq_percentage = random.uniform(0.0, freq_masking)\n",
    "\n",
    "        num_freqs_to_mask = int(freq_percentage * all_freqs_num)\n",
    "        f0 = np.random.uniform(low=0.0, high=all_freqs_num - num_freqs_to_mask)\n",
    "        f0 = int(f0)\n",
    "        spec[f0:f0 + num_freqs_to_mask, :] = value\n",
    "\n",
    "        time_percentage = random.uniform(0.0, time_masking)\n",
    "\n",
    "        num_frames_to_mask = int(time_percentage * all_frames_num)\n",
    "        t0 = np.random.uniform(low=0.0, high=all_frames_num - num_frames_to_mask)\n",
    "        t0 = int(t0)\n",
    "        spec[:, t0:t0 + num_frames_to_mask] = value\n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bfa25201",
   "metadata": {
    "papermill": {
     "duration": 0.028457,
     "end_time": "2024-04-09T07:43:38.868852",
     "exception": false,
     "start_time": "2024-04-09T07:43:38.840395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Source: https://github.com/lRomul/argus-freesound/blob/master/src/transforms.py\n",
    "class SpecAugment:\n",
    "    def __init__(self,\n",
    "                 num_mask=2,\n",
    "                 freq_masking=0.15,\n",
    "                 time_masking=0.20):\n",
    "        self.num_mask = num_mask\n",
    "        self.freq_masking = freq_masking\n",
    "        self.time_masking = time_masking\n",
    "\n",
    "    def __call__(self, image):\n",
    "        return spec_augment(image,\n",
    "                            self.num_mask,\n",
    "                            self.freq_masking,\n",
    "                            self.time_masking,\n",
    "                            image.min())\n",
    "\n",
    "class Compose:\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, image, trg=None):\n",
    "        if trg is None:\n",
    "            for t in self.transforms:\n",
    "                image = t(image)\n",
    "            return image\n",
    "        else:\n",
    "            for t in self.transforms:\n",
    "                image, trg = t(image, trg)\n",
    "            return image, trg\n",
    "        \n",
    "class UseWithProb:\n",
    "    def __init__(self, transform, prob=.5):\n",
    "        self.transform = transform\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, image, trg=None):\n",
    "        if trg is None:\n",
    "            if random.random() < self.prob:\n",
    "                image = self.transform(image)\n",
    "            return image\n",
    "        else:\n",
    "            if random.random() < self.prob:\n",
    "                image, trg = self.transform(image, trg)\n",
    "            return image, trg\n",
    "        \n",
    "class OneOf:\n",
    "    def __init__(self, transforms, p=None):\n",
    "        self.transforms = transforms\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, image, trg=None):\n",
    "        transform = np.random.choice(self.transforms, p=self.p)\n",
    "        if trg is None:\n",
    "            image = transform(image)\n",
    "            return image\n",
    "        else:\n",
    "            image, trg = transform(image, trg)\n",
    "            return image, trg\n",
    "        \n",
    "class ImageToTensor:\n",
    "    def __call__(self, image):\n",
    "        delta = librosa.feature.delta(image)\n",
    "        accelerate = librosa.feature.delta(image, order=2)\n",
    "        image = np.stack([image, delta, accelerate], axis=0)\n",
    "        # image = np.stack([image, image, image], axis=0)\n",
    "        image = image.astype(np.float32) / 100\n",
    "        image = torch.from_numpy(image)\n",
    "        return image\n",
    "    \n",
    "class RandomCrop:\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self, signal):\n",
    "        start = random.randint(0, signal.shape[1] - self.size)\n",
    "        return signal[:, start: start + self.size]\n",
    "\n",
    "class CenterCrop:\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self, signal):\n",
    "\n",
    "        if signal.shape[1] > self.size:\n",
    "            start = (signal.shape[1] - self.size) // 2\n",
    "            return signal[:, start: start + self.size]\n",
    "        else:\n",
    "            return signal\n",
    "        \n",
    "class PadToSize:\n",
    "    def __init__(self, size, mode='constant'):\n",
    "        assert mode in ['constant', 'wrap']\n",
    "        self.size = size\n",
    "        self.mode = mode\n",
    "\n",
    "    def __call__(self, signal):\n",
    "        if signal.shape[1] < self.size:\n",
    "            padding = self.size - signal.shape[1]\n",
    "            offset = padding // 2\n",
    "            pad_width = ((0, 0), (offset, padding - offset))\n",
    "            if self.mode == 'constant':\n",
    "                signal = np.pad(signal, pad_width,\n",
    "                                'constant', constant_values=signal.min())\n",
    "            else:\n",
    "                signal = np.pad(signal, pad_width, 'wrap')\n",
    "        return signal\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "fcdc8ec5",
   "metadata": {
    "papermill": {
     "duration": 0.015654,
     "end_time": "2024-04-09T07:43:38.890637",
     "exception": false,
     "start_time": "2024-04-09T07:43:38.874983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_transforms(train, size,\n",
    "                   wrap_pad_prob=0.5,\n",
    "                   resize_prob=0.33,\n",
    "                   spec_num_mask=2,\n",
    "                   spec_freq_masking=0.15,\n",
    "                   spec_time_masking=0.20,\n",
    "                   spec_prob=0.5):\n",
    "    if train:\n",
    "        transforms = Compose([\n",
    "            OneOf([\n",
    "                PadToSize(size, mode='wrap'),\n",
    "                PadToSize(size, mode='constant'),\n",
    "            ], p=[wrap_pad_prob, 1 - wrap_pad_prob]),\n",
    "            PadToSize(size),\n",
    "            RandomCrop(size),\n",
    "            UseWithProb(SpecAugment(num_mask=spec_num_mask,\n",
    "                                    freq_masking=spec_freq_masking,\n",
    "                                    time_masking=spec_time_masking), spec_prob),\n",
    "            ImageToTensor()\n",
    "        ])\n",
    "    else:\n",
    "        transforms = Compose([\n",
    "            PadToSize(size),\n",
    "            CenterCrop(size),\n",
    "            ImageToTensor()\n",
    "        ])\n",
    "    return transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0fa8f80e",
   "metadata": {
    "papermill": {
     "duration": 0.014639,
     "end_time": "2024-04-09T07:43:38.911509",
     "exception": false,
     "start_time": "2024-04-09T07:43:38.896870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_as_melspectrogram(file_path):\n",
    "    y, sr = librosa.load(file_path, sr=48000)\n",
    "    yt, idx = librosa.effects.trim(y) \n",
    "\n",
    "    spectrogram = librosa.feature.melspectrogram(y=yt,\n",
    "                                                 sr=48000,\n",
    "                                                 n_mels=150,\n",
    "                                                 hop_length=345 * 5,                                            \n",
    "                                                 n_fft=315 * 20,\n",
    "                                                 fmin=20,\n",
    "                                                 fmax=48000//4)\n",
    "                                                \n",
    "    spectrogram = librosa.power_to_db(spectrogram)\n",
    "    spectrogram = spectrogram.astype(np.float32)\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "9f2d739b",
   "metadata": {
    "papermill": {
     "duration": 0.013859,
     "end_time": "2024-04-09T07:43:38.931363",
     "exception": false,
     "start_time": "2024-04-09T07:43:38.917504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data(indexes, wav_paths):\n",
    "    folds_df = pd.read_csv(\"data/label_data.csv\", delimiter=\";\")\n",
    "    targets_lst = folds_df.loc[indexes][\"label\"]\n",
    "\n",
    "    images_lst = []\n",
    "    for i in wav_paths:\n",
    "        images_lst.append(read_as_melspectrogram(i))\n",
    "\n",
    "    return list(targets_lst), images_lst "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8b097afc",
   "metadata": {
    "papermill": {
     "duration": 0.017508,
     "end_time": "2024-04-09T07:43:38.954875",
     "exception": false,
     "start_time": "2024-04-09T07:43:38.937367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NewDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, transform=None, train=True, seed=1):\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.wav_path = []\n",
    "        for wav_path in sorted(root.glob('*.wav')):\n",
    "            self.wav_path.append(wav_path)\n",
    "        \n",
    "        np.random.seed(seed)\n",
    "        permutation = np.random.permutation(len(self.wav_path))\n",
    "        \n",
    "        # Train/test split\n",
    "        if train:\n",
    "            self.indexes = permutation[: int(len(self.wav_path) * 0.8)].tolist()\n",
    "        else:\n",
    "            self.indexes = permutation[int(len(self.wav_path) * 0.8) :].tolist()\n",
    "  \n",
    "        self.wav_path = [self.wav_path[wav] for wav in self.indexes]\n",
    "        \n",
    "        self.target, self.image = get_data(self.indexes, self.wav_path)\n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.image[idx]\n",
    "        target = self.target[idx]\n",
    "        \n",
    "        return self.transform(image=image), target\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2c5140d7",
   "metadata": {
    "papermill": {
     "duration": 0.013138,
     "end_time": "2024-04-09T07:43:38.973912",
     "exception": false,
     "start_time": "2024-04-09T07:43:38.960774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_transfrom = get_transforms(train=True,\n",
    "                                     size=256,\n",
    "                                     wrap_pad_prob=0.5,\n",
    "                                     resize_prob=0.33,\n",
    "                                     spec_num_mask=2,\n",
    "                                     spec_freq_masking=0.15,\n",
    "                                     spec_time_masking=0.20,\n",
    "                                     spec_prob=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "147f6acb",
   "metadata": {
    "papermill": {
     "duration": 268.210112,
     "end_time": "2024-04-09T07:48:07.189871",
     "exception": false,
     "start_time": "2024-04-09T07:43:38.979759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds = NewDataset(root=Path(\"data/all_denoised_audio_files\"), transform=train_transfrom, train=True)\n",
    "test_ds = NewDataset(root=Path(\"data/all_denoised_audio_files\"), transform=get_transforms(False, 256), train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f59e6c3a",
   "metadata": {
    "papermill": {
     "duration": 0.017252,
     "end_time": "2024-04-09T07:48:07.214934",
     "exception": false,
     "start_time": "2024-04-09T07:48:07.197682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_workers = 4\n",
    "pin_memory =True\n",
    "train_dl = DataLoader(train_ds, batch_size, True, num_workers=num_workers, pin_memory=pin_memory)\n",
    "val_dl = DataLoader(test_ds, 1, True, num_workers=num_workers, pin_memory=pin_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e928f1",
   "metadata": {
    "papermill": {
     "duration": 0.007727,
     "end_time": "2024-04-09T07:48:07.230629",
     "exception": false,
     "start_time": "2024-04-09T07:48:07.222902",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "1902df1b",
   "metadata": {
    "papermill": {
     "duration": 0.032266,
     "end_time": "2024-04-09T07:48:07.270799",
     "exception": false,
     "start_time": "2024-04-09T07:48:07.238533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = F.avg_pool2d(x, 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class IdentityBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, scale_factor=2):\n",
    "        super(IdentityBlock, self).__init__()\n",
    "\n",
    "        self.conv_block = nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False)\n",
    "        self.batch = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.scale_factor = scale_factor\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.scale_factor >= 2:\n",
    "            x = F.avg_pool2d(x, self.scale_factor)\n",
    "        x = self.conv_block(x)\n",
    "        x = self.batch(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_classes=2, base_size=64,\n",
    "                 dropout=0.2, ratio=16, kernel_size=7,\n",
    "                 last_filters=8, last_fc=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_block1 = ConvBlock(in_channels=3, out_channels=base_size)\n",
    "        self.iden1 = IdentityBlock(in_channels=base_size, out_channels=base_size*8,\n",
    "                               scale_factor=8)\n",
    "\n",
    "        self.conv_block2 = ConvBlock(in_channels=base_size, out_channels=base_size*2)\n",
    "        self.iden2 = IdentityBlock(in_channels=base_size * 2, out_channels=base_size*8,\n",
    "                               scale_factor=4)\n",
    "\n",
    "        self.conv_block3 = ConvBlock(in_channels=base_size*2, out_channels=base_size*4)\n",
    "        self.iden3 = IdentityBlock(in_channels=base_size*4, out_channels=base_size*8,\n",
    "                               scale_factor=2)\n",
    "\n",
    "        self.conv_block4 = ConvBlock(in_channels=base_size*4, out_channels=base_size*8)\n",
    "\n",
    "        self.merge = IdentityBlock(base_size*8*4, base_size*last_filters, 1)\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.lin = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(base_size*last_filters, base_size*last_fc),\n",
    "            nn.PReLU(),\n",
    "            nn.BatchNorm1d(base_size*last_fc),\n",
    "            nn.Dropout(dropout/2),\n",
    "            nn.Linear(base_size*last_fc, num_classes),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block1(x)\n",
    "        iden1 = self.iden1(x)\n",
    "\n",
    "        x = self.conv_block2(x)\n",
    "        iden2 = self.iden2(x)\n",
    "\n",
    "        x = self.conv_block3(x)\n",
    "        iden3 = self.iden3(x)\n",
    "\n",
    "        x = self.conv_block4(x)\n",
    "\n",
    "        x = torch.cat([x, iden1, iden2, iden3], dim=1)\n",
    "\n",
    "        x = self.merge(x)\n",
    "\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.lin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "8e88c44d",
   "metadata": {
    "papermill": {
     "duration": 1.480444,
     "end_time": "2024-04-09T07:48:08.759760",
     "exception": false,
     "start_time": "2024-04-09T07:48:07.279316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "leaing_rate = 0.0005\n",
    "\n",
    "loss_fun=CrossEntropyLoss()\n",
    "\n",
    "net=Model().cuda()\n",
    "\n",
    "opt = torch.optim.Adam(params=net.parameters(), lr=leaing_rate) \n",
    "lr_decay = torch.optim.lr_scheduler.StepLR(opt, step_size=10, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "b4c64fa4",
   "metadata": {
    "papermill": {
     "duration": 0.015012,
     "end_time": "2024-04-09T07:48:08.783054",
     "exception": false,
     "start_time": "2024-04-09T07:48:08.768042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "8f807104",
   "metadata": {
    "papermill": {
     "duration": 181.383595,
     "end_time": "2024-04-09T07:51:10.174713",
     "exception": false,
     "start_time": "2024-04-09T07:48:08.791118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed_everything(123)\n",
    "\n",
    "for epoch in range(100):\n",
    "    net.train()\n",
    "\n",
    "    mean_loss = []\n",
    "\n",
    "    for batch in train_dl:\n",
    "    \n",
    "        images, targets = batch[0], batch[1]\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "        \n",
    "        predictions = net(images)\n",
    "\n",
    "        # calculating loss\n",
    "        loss = loss_fun(predictions, targets)\n",
    "\n",
    "        # backward pass\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        lr_decay.step()\n",
    "\n",
    "        mean_loss.append(loss.item())\n",
    "        \n",
    "    #print(f\"Epoch {epoch} done Train loss {np.mean(mean_loss):.3f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "1196f522-cbbf-419d-8360-8c6e2d62c1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in model.pth\n"
     ]
    }
   ],
   "source": [
    "model_path = \"model.pth\"\n",
    "torch.save(net.state_dict(), model_path)\n",
    "print(f\"Model saved in {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "a7845e81",
   "metadata": {
    "papermill": {
     "duration": 0.028899,
     "end_time": "2024-04-09T07:51:10.219584",
     "exception": false,
     "start_time": "2024-04-09T07:51:10.190685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validation(model, optimizer, test_loader,isval=True):\n",
    "    model.eval()\n",
    "    pre_all=[]\n",
    "    tre_all=[]\n",
    "\n",
    "    test_loss = 0\n",
    "    all_y = []\n",
    "    all_y_pred = []\n",
    "\n",
    "    prob_all=[]\n",
    "    num = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y  in test_loader:\n",
    "            all_y.append(y.cpu().numpy())\n",
    "            tre=y\n",
    "            y = y.type(torch.LongTensor).cuda()\n",
    "            num=num+1\n",
    "\n",
    "            # distribute data to device\n",
    "            X= X.cuda()\n",
    "\n",
    "            outputs = model(X)\n",
    "\n",
    "            loss= loss_fun(outputs, y)\n",
    "\n",
    "            mask=outputs.cpu().numpy()\n",
    "\n",
    "            tmp_prob=mask[:,1]\n",
    "\n",
    "            prob_all.extend(tmp_prob)\n",
    "\n",
    "            tmp=np.argmax(mask, 1)\n",
    "\n",
    "            all_y_pred.append(tmp)\n",
    "\n",
    "            test_loss += loss.item()  \n",
    "\n",
    "    test_loss /= num\n",
    "    test_loss=test_loss\n",
    "\n",
    "    y_true=np.array(all_y)\n",
    "    y_pre=np.array(all_y_pred)\n",
    "\n",
    "    acc_sk = round(accuracy_score(y_true, y_pre), 2)\n",
    "    precis = round(precision_score(y_true, y_pre), 2)\n",
    "    recall = round(recall_score(y_true, y_pre), 2)\n",
    "    f1 = round(f1_score(y_true, y_pre), 2)\n",
    "    roc_auc = round(roc_auc_score(y_true, y_pre), 2)\n",
    "    test_loss = round(test_loss, 2)\n",
    "\n",
    "\n",
    "    return f'test_loss = {test_loss}, accuracy = {acc_sk}, precision = {precis}, recall = {recall}, f1 = {f1}, roc auc = {roc_auc}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "391ae550",
   "metadata": {
    "papermill": {
     "duration": 0.64634,
     "end_time": "2024-04-09T07:51:10.881457",
     "exception": false,
     "start_time": "2024-04-09T07:51:10.235117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss = 0.37, accuracy = 0.89, precision = 0.86, recall = 0.93, f1 = 0.89, roc auc = 0.91\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "\n",
    "metric = validation(net, opt, val_dl)\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc664be",
   "metadata": {
    "papermill": {
     "duration": 0.015495,
     "end_time": "2024-04-09T07:51:10.913448",
     "exception": false,
     "start_time": "2024-04-09T07:51:10.897953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4438814,
     "sourceId": 7620535,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4611478,
     "sourceId": 7861152,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4612183,
     "sourceId": 7862156,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4616813,
     "sourceId": 7868646,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4618040,
     "sourceId": 7870321,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4618088,
     "sourceId": 7870395,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4618576,
     "sourceId": 7871132,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4618585,
     "sourceId": 7871152,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30683,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "sc-new-g1YLDtZZ-py3.12",
   "language": "python",
   "name": "sc-new-g1yldtzz-py3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 475.411452,
   "end_time": "2024-04-09T07:51:14.087253",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-09T07:43:18.675801",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
